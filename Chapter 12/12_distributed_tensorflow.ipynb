{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfpFtMRsWx6G"
      },
      "source": [
        "**Chapter 12 – Distributed TensorFlow**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "45TUsuB5Wx6R"
      },
      "outputs": [],
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 1.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"distributed\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bgwh3VKiWx6V"
      },
      "source": [
        "# Local server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "s5d9Z8lDWx6X"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v2 as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7FgzMPPdWx6g"
      },
      "outputs": [],
      "source": [
        "c = tf.constant(\"Hello distributed TensorFlow!\")\n",
        "server = tf.train.Server.create_local_server()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0TmLg6e-Wx6j",
        "outputId": "52817900-1431-44a1-c4c0-c4057a0b4fe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'Hello distributed TensorFlow!'\n"
          ]
        }
      ],
      "source": [
        "with tf.Session(server.target) as sess:\n",
        "    print(sess.run(c))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf2"
      ],
      "metadata": {
        "id": "pQD7s8wxYdE5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz-MpXEUWx6n"
      },
      "source": [
        "# Loss function "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "you want to train a regression model, but your training set is a bit noisy. Of\n",
        "course, you start by trying to clean up your dataset by removing or fixing the outliers,\n",
        "but it turns out to be insufficient, the dataset is still noisy. Which loss function should\n",
        "you use? The mean squared error might penalize large errors too much, so your\n",
        "model will end up being imprecise. The mean absolute error would not penalize out‐\n",
        "liers as much, but training might take a while to converge and the trained model\n",
        "might not be very precise. This is probably a good time to use the Huber loss (intro‐\n",
        "duced in Chapter 10) instead of the good old MSE. The Huber loss is not currently\n",
        "part of the official Keras API, but it is available in tf.keras (just use an instance of the\n",
        "keras.losses.Huber class)."
      ],
      "metadata": {
        "id": "6bh24qUKY3iG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bm63cC1RWx6o"
      },
      "outputs": [],
      "source": [
        "def huber_fn(y_true, y_pred):\n",
        " error = y_true - y_pred\n",
        " is_small_error = tf.abs(error) < 1\n",
        " squared_loss = tf.square(error) / 2\n",
        " linear_loss = tf.abs(error) - 0.5\n",
        " return tf.where(is_small_error, squared_loss, linear_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, you can just use this loss when you compile the Keras model, then train your model:"
      ],
      "metadata": {
        "id": "OO9BueuJZDp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=huber_fn, optimizer=\"nadam\")\n",
        "model.fit(X_train, y_train, [...])"
      ],
      "metadata": {
        "id": "LhrzcOEdZAZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving a model containing a custom loss function actually works fine, as Keras just\n",
        "saves the name of the function. However, whenever you load it, you need to provide a\n",
        "dictionary that maps the function name to the actual function. More generally, when\n",
        "you load a model containing custom objects, you need to map the names to the\n",
        "objects:\n"
      ],
      "metadata": {
        "id": "WRmUqfkyZJDg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0_YvstJWx6p"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
        " custom_objects={\"huber_fn\": huber_fn})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "or we could use the HuberLoss class by using keras.losses.loss subclass and We will use custom object for sure after saving and calling the model again"
      ],
      "metadata": {
        "id": "DPCkyj9NZNnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "class HuberLoss(keras.losses.Loss):\n",
        " def __init__(self, threshold=1.0, **kwargs):\n",
        "    self.threshold = threshold\n",
        "    super().__init__(**kwargs)\n",
        " def call(self, y_true, y_pred):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) < self.threshold\n",
        "    squared_loss = tf.square(error) / 2\n",
        "    linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
        " def get_config(self):\n",
        "    base_config = super().get_config()\n",
        "    return {**base_config, \"threshold\": self.threshold}"
      ],
      "metadata": {
        "id": "R6yQ8v2ZZMmp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example"
      ],
      "metadata": {
        "id": "LDLHu9qhaFhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
        "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "\n",
        "raw_dataset = pd.read_csv(url, names=column_names,\n",
        "                          na_values='?', comment='\\t',\n",
        "                          sep=' ', skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.tail()"
      ],
      "metadata": {
        "id": "WfmZN6PhaAii",
        "outputId": "da61dce2-b649-499a-cde3-eb07d237cc4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
              "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
              "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
              "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
              "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
              "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
              "\n",
              "     Model Year  Origin  \n",
              "393          82       1  \n",
              "394          82       2  \n",
              "395          82       1  \n",
              "396          82       1  \n",
              "397          82       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f05dd0c1-dc7a-4781-84ae-4367c093a490\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MPG</th>\n",
              "      <th>Cylinders</th>\n",
              "      <th>Displacement</th>\n",
              "      <th>Horsepower</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Acceleration</th>\n",
              "      <th>Model Year</th>\n",
              "      <th>Origin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>27.0</td>\n",
              "      <td>4</td>\n",
              "      <td>140.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>2790.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>44.0</td>\n",
              "      <td>4</td>\n",
              "      <td>97.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>2130.0</td>\n",
              "      <td>24.6</td>\n",
              "      <td>82</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>32.0</td>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>28.0</td>\n",
              "      <td>4</td>\n",
              "      <td>120.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>2625.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>31.0</td>\n",
              "      <td>4</td>\n",
              "      <td>119.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f05dd0c1-dc7a-4781-84ae-4367c093a490')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f05dd0c1-dc7a-4781-84ae-4367c093a490 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f05dd0c1-dc7a-4781-84ae-4367c093a490');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.dropna()"
      ],
      "metadata": {
        "id": "7AzT0kElaHaE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
        "\n",
        "dataset = pd.get_dummies(dataset, columns=['Origin'], prefix='', prefix_sep='')\n",
        "dataset.tail()"
      ],
      "metadata": {
        "id": "YE02d6c6aLfL",
        "outputId": "6241d0e2-2717-4b54-d6a0-37e3eb6e7878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
              "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
              "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
              "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
              "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
              "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
              "\n",
              "     Model Year  Europe  Japan  USA  \n",
              "393          82       0      0    1  \n",
              "394          82       1      0    0  \n",
              "395          82       0      0    1  \n",
              "396          82       0      0    1  \n",
              "397          82       0      0    1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57ef8685-6209-4d90-ab50-bfb423acf2cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MPG</th>\n",
              "      <th>Cylinders</th>\n",
              "      <th>Displacement</th>\n",
              "      <th>Horsepower</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Acceleration</th>\n",
              "      <th>Model Year</th>\n",
              "      <th>Europe</th>\n",
              "      <th>Japan</th>\n",
              "      <th>USA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>27.0</td>\n",
              "      <td>4</td>\n",
              "      <td>140.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>2790.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>44.0</td>\n",
              "      <td>4</td>\n",
              "      <td>97.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>2130.0</td>\n",
              "      <td>24.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>32.0</td>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>28.0</td>\n",
              "      <td>4</td>\n",
              "      <td>120.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>2625.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>31.0</td>\n",
              "      <td>4</td>\n",
              "      <td>119.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57ef8685-6209-4d90-ab50-bfb423acf2cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57ef8685-6209-4d90-ab50-bfb423acf2cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57ef8685-6209-4d90-ab50-bfb423acf2cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ],
      "metadata": {
        "id": "gij2RDn-aPc1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "\n",
        "train_labels = train_features.pop('MPG')\n",
        "test_labels = test_features.pop('MPG')"
      ],
      "metadata": {
        "id": "V1e4QF1qanuH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "horsepower = np.array(train_features['Horsepower'])\n",
        "\n",
        "horsepower_normalizer = layers.Normalization(input_shape=[1,], axis=None)\n",
        "horsepower_model = tf.keras.Sequential([\n",
        "    horsepower_normalizer,\n",
        "    layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "horsepower_model.summary()"
      ],
      "metadata": {
        "id": "nERpWJlsaSZw",
        "outputId": "6b27706f-3e08-4d0c-b78e-30f494ec5544",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization_10 (Normaliza  (None, 1)                3         \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5\n",
            "Trainable params: 2\n",
            "Non-trainable params: 3\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "horsepower_model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "    loss=HuberLoss(2.))"
      ],
      "metadata": {
        "id": "xKKY6ZltbnmY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myl-sov_Wx6r"
      },
      "source": [
        "# Custom Activation Functions, Initializers, Regularizers, and Constraints"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most Keras functionalities, such as losses, regularizers, constraints, initializers, met‐\n",
        "rics, activation functions, layers and even full models can be customized in very much\n",
        "the same way. Most of the time, you will just need to write a simple function, with the\n",
        "appropriate inputs and outputs. For example, here are examples of a custom activa‐\n",
        "tion function (equivalent to keras.activations.softplus or tf.nn.softplus), a\n",
        "custom Glorot initializer (equivalent to keras.initializers.glorot_normal), a cus‐\n",
        "tom ℓ1\n",
        " regularizer (equivalent to keras.regularizers.l1(0.01)) and a custom con‐\n",
        "straint that ensures weights are all positive (equivalent to\n",
        "keras.constraints.nonneg() or tf.nn.relu):"
      ],
      "metadata": {
        "id": "j9dEM3MfcOqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_softplus(z): \n",
        " return tf.math.log(tf.exp(z) + 1.0)\n",
        "\n",
        "def my_glorot_initializer(shape, dtype=tf.float32):\n",
        " stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
        " return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
        "\n",
        "def my_l1_regularizer(weights):\n",
        " return tf.reduce_sum(tf.abs(0.01 * weights))\n",
        "\n",
        "def my_positive_weights(weights): \n",
        "   return tf.where(weights < 0., tf.zeros_like(weights), weights)\n"
      ],
      "metadata": {
        "id": "MEWkOyptcOUg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "jRdQP0IbWx6s"
      },
      "outputs": [],
      "source": [
        "layer = keras.layers.Dense(30, activation=my_softplus,\n",
        " kernel_initializer=my_glorot_initializer,\n",
        " kernel_regularizer=my_l1_regularizer,\n",
        " kernel_constraint=my_positive_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could save the function and doing the same as we did in the loss function by creating sub class here is an example:\n"
      ],
      "metadata": {
        "id": "F8iEliIVc9mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
        " def __init__(self, factor):\n",
        "     self.factor = factor\n",
        " def __call__(self, weights):\n",
        "     return tf.reduce_sum(tf.abs(self.factor * weights))\n",
        " def get_config(self):\n",
        "     return {\"factor\": self.factor}\n"
      ],
      "metadata": {
        "id": "cSSSm44hdFJq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vFOTd5KWx6y"
      },
      "source": [
        "# Custom Metrics\n",
        "\n",
        "Losses and metrics are conceptually not the same thing: losses are used by Gradient\n",
        "Descent to train a model, so they must be differentiable (at least where they are evalu‐\n",
        "ated) and their gradients should not be 0 everywhere. Plus, it’s okay if they are not\n",
        "easily interpretable by humans (e.g. cross-entropy). In contrast, metrics are used to\n",
        "evaluate a model, they must be more easily interpretable, and they can be nondifferentiable or have 0 gradients everywhere (e.g., accuracy)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That said, in most cases, defining a custom metric function is exactly the same as\n",
        "defining a custom loss function. In fact, we could even use the Huber loss function we\n",
        "created earlier as a metric6\n",
        ", it would work just fine (and persistence would also work\n",
        "the same way, in this case only saving the name of the function, \"huber_fn\"):"
      ],
      "metadata": {
        "id": "M_JFyphGBZ5t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWe_owN4Wx6y"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you define a metric using a simple function, Keras automatically calls it for\n",
        "each batch, and it keeps track of the mean during each epoch, just like we did man‐\n",
        "ually. So the only benefit of our HuberMetric class is that the threshold will be saved.\n"
      ],
      "metadata": {
        "id": "v4PgMEpFE3vN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8yg7vwkWx63"
      },
      "source": [
        "# Custom Layers\n",
        "You may occasionally want to build an architecture that contains an exotic layer for\n",
        "which TensorFlow does not provide a default implementation. In this case, you will\n",
        "need to create a custom layer. Or sometimes you may simply want to build a very\n",
        "repetitive architecture, containing identical blocks of layers repeated many times, and\n",
        "it would be convenient to treat each block of layers as a single layer. For example, if\n",
        "the model is a sequence of layers A, B, C, A, B, C, A, B, C, then you might want to\n",
        "define a custom layer D containing layers A, B, C, and your model would then simply\n",
        "be D, D, D. Let’s see how to build custom layers.\n",
        "First, some layers have no weights, such as keras.layers.Flatten or keras.lay\n",
        "ers.ReLU. If you want to create a custom layer without any weights, the simplest\n",
        "option is to write a function and wrap it in a keras.layers.Lambda layer. For exam‐\n",
        "ple, the following layer will apply the exponential function to its inputs:\n",
        "\n",
        "you can use it as activation function as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XpdoIVP0Wx64"
      },
      "outputs": [],
      "source": [
        "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "you need to create a subclass of the keras.layers.Layer class. For exam‐\n",
        "ple, the following class implements a simplified version of the Dense layer:\n"
      ],
      "metadata": {
        "id": "NfinKZymFpvs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jae3MY0QWx65"
      },
      "outputs": [],
      "source": [
        "class MyDense(keras.layers.Layer):\n",
        " def __init__(self, units, activation=None, **kwargs):\n",
        "  super().__init__(**kwargs)\n",
        "  self.units = units\n",
        "  self.activation = keras.activations.get(activation)\n",
        " def build(self, batch_input_shape):\n",
        "  self.kernel = self.add_weight(\n",
        "  name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
        "  initializer=\"glorot_normal\")\n",
        "  self.bias = self.add_weight(\n",
        "  name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
        "  super().build(batch_input_shape) # must be at the end\n",
        " def call(self, X):\n",
        "  return self.activation(X @ self.kernel + self.bias)\n",
        " def compute_output_shape(self, batch_input_shape):\n",
        "  return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
        "def get_config(self):\n",
        "  base_config = super().get_config()\n",
        "  return {**base_config, \"units\": self.units,\"activation\": keras.activations.serialize(self.activation)}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your layer needs to have a different behavior during training and during testing\n",
        "(e.g., if it uses Dropout or BatchNormalization layers), then you must add a train\n",
        "ing argument to the call() method and use this argument to decide what to do. For\n",
        "example, let’s create a layer that adds Gaussian noise during training (for regulariza‐\n",
        "tion), but does nothing during testing (Keras actually has a layer that does the same\n",
        "thing: keras.layers.GaussianNoise):"
      ],
      "metadata": {
        "id": "mycbdJXgHlsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGaussianNoise(keras.layers.Layer):\n",
        " def __init__(self, stddev, **kwargs):\n",
        "  super().__init__(**kwargs)\n",
        "  self.stddev = stddev\n",
        " def call(self, X, training=None):\n",
        "  if training:\n",
        "   noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
        "   return X + noise\n",
        "  else:\n",
        "    return X\n",
        " def compute_output_shape(self, batch_input_shape):\n",
        "  return batch_input_shape\n"
      ],
      "metadata": {
        "id": "8ckbd5s7HnBM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeaP-bLmWx66"
      },
      "source": [
        "# Custom Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we mentioned in chapter 10 there is some custom model we can create and here is an one of example of it  , we would explain and do it more on chapter 14 "
      ],
      "metadata": {
        "id": "4gQIJcTUHztP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kHdJgzfSWx66"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(keras.layers.Layer):\n",
        " def __init__(self, n_layers, n_neurons, **kwargs):\n",
        "  super().__init__(**kwargs)\n",
        "  self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
        "  kernel_initializer=\"he_normal\")\n",
        "  for _ in range(n_layers)]\n",
        " def call(self, inputs):\n",
        "  Z = inputs\n",
        "  for layer in self.hidden:\n",
        "   Z = layer(Z)\n",
        "  return inputs + Z"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualRegressor(keras.models.Model):\n",
        " def __init__(self, output_dim, **kwargs):\n",
        "  super().__init__(**kwargs)\n",
        "  self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
        "  kernel_initializer=\"he_normal\")\n",
        "  self.block1 = ResidualBlock(2, 30)\n",
        "  self.block2 = ResidualBlock(2, 30)\n",
        "  self.out = keras.layers.Dense(output_dim)\n",
        " def call(self, inputs):\n",
        "  Z = self.hidden1(inputs)\n",
        "  for _ in range(1 + 3):\n",
        "    Z = self.block1(Z)\n",
        "    Z = self.block2(Z)\n",
        "  return self.out(Z)"
      ],
      "metadata": {
        "id": "K_eUXvRbIjXH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create the layers in the constructor, and use them in the call() method. This\n",
        "model can then be used like any other model (compile it, fit it, evaluate it and use it to\n",
        "make predictions). If you also want to be able to save the model using the save()\n",
        "method, and load it using the keras.models.load_model() function, you must\n",
        "implement the get_config() method (as we did earlier) in both the ResidualBlock\n",
        "class and the ResidualRegressor class. Alternatively, you can just save and load the\n",
        "weights using the save_weights() and load_weights() methods."
      ],
      "metadata": {
        "id": "b3355TkbI1X-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Losses and Metrics Based on Model Internals\n",
        "\n",
        "The custom losses and metrics we defined earlier were all based on the labels and the\n",
        "predictions (and optionally sample weights). However, you will occasionally want to\n",
        "define losses based on other parts of your model, such as the weights or activations of\n",
        "its hidden layers. This may be useful for regularization purposes, or to monitor some\n",
        "internal aspect of your model"
      ],
      "metadata": {
        "id": "BRYd48s4Jsfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Training Loops\n",
        "\n",
        "In some rare cases, the fit() method may not be flexible enough for what you need\n",
        "to do. For example, the Wide and Deep paper we discussed in Chapter 10 actually\n",
        "uses two different optimizers: one for the wide path and the other for the deep path.\n",
        "\n",
        "Since the fit() method only uses one optimizer (the one that we specify when compiling the model), implementing this paper requires writing your own custom\n",
        "loop.\n",
        "\n",
        "You may also like to write your own custom training loops simply to feel more confident that it does precisely what you intent it to do (perhaps you are unsure about\n",
        "some details of the fit() method). It can sometimes feel safer to make everything\n",
        "explicit. However, remember that writing a custom training loop will make your code\n",
        "longer, more error prone and harder to maintain.\n"
      ],
      "metadata": {
        "id": "n1N9-y6RNq6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a tiny function that will randomly sample a batch of instances from the training set\n",
        "def random_batch(X, y, batch_size=32):\n",
        " idx = np.random.randint(len(X), size=batch_size)\n",
        " return X[idx], y[idx]\n",
        "\n",
        "''''\n",
        "Let’s also define a function that will display the training status, including the number\n",
        "of steps, the total number of steps, the mean loss since the start of the epoch (i.e., we\n",
        "will use the Mean metric to compute it), and other metrics\n",
        "'''''\n",
        "def print_status_bar(iteration, total, loss, metrics=None):\n",
        " metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
        " for m in [loss] + (metrics or [])])\n",
        " end = \"\" if iteration < total else \"\\n\"\n",
        " print(\"\\r{}/{} - \".format(iteration, total) + metrics,\n",
        " end=end)"
      ],
      "metadata": {
        "id": "TLldGm--OBGO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit implementation \n",
        "for epoch in range(1, n_epochs + 1):\n",
        " print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
        " for step in range(1, n_steps + 1):\n",
        "  X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
        "  with tf.GradientTape() as tape:\n",
        "     y_pred = model(X_batch, training=True)\n",
        "     main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "     loss = tf.add_n([main_loss] + model.losses)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  mean_loss(loss)\n",
        "  for metric in metrics:\n",
        "   metric(y_batch, y_pred)\n",
        "   print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
        "   print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
        "  for metric in [mean_loss] + metrics:\n",
        "    metric.reset_states()"
      ],
      "metadata": {
        "id": "N8UZxW0eOEai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moreover, when you write a custom loss function, a custom metric, a custom layer or\n",
        "any other custom function, and you use it in a Keras model (as we did throughout\n",
        "this chapter), Keras automatically converts your function into a TF Function, no need\n",
        "to use tf.function(). So most of the time, all this magic is 100% transparent."
      ],
      "metadata": {
        "id": "KvuimaaNPsyc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF Function generates a new graph for every unique set of input shapes and data\n",
        "types, and it caches it for subsequent calls. For example, if you call tf_cube(tf.con\n",
        "stant(10)), a graph will be generated for int32 tensors of shape []. Then if you call\n",
        "tf_cube(tf.constant(20)), the same graph will be reused. But if you then call\n",
        "tf_cube(tf.constant([10, 20])), a new graph will be generated for int32 tensors\n",
        "of shape [2]. This is how TF Functions handle polymorphism (i.e., varying argument\n",
        "types and shapes). However, this is only true for tensor arguments: if you pass numer‐\n",
        "ical Python values to a TF Function, a new graph will be generated for every distinct\n",
        "value: for example, calling tf_cube(10) and tf_cube(20) will generate two graphs."
      ],
      "metadata": {
        "id": "Gmlm9nJcP7a9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you call a TF Function many times with different numerical\n",
        "Python values, then many graphs will be generated, slowing down\n",
        "your program and using up a lot of RAM. Python values should be\n",
        "reserved for arguments that will have few unique values, such as\n",
        "hyperparameters like the number of neurons per layer. This allows\n",
        "TensorFlow to better optimize each variant of your model.\n"
      ],
      "metadata": {
        "id": "byg3UbtAP_c-"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}