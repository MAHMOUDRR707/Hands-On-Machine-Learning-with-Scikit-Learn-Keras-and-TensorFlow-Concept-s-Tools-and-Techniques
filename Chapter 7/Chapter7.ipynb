{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICov7hrTrefj"
      },
      "source": [
        "# Chapter 7 Answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHq_LsPkrVqW"
      },
      "source": [
        "**If you have trained five different models on the exact same training data, and they all achieve 95% precision, is there any chance that you can combine these models to get better results? If so, how? If not, why?**\n",
        "\n",
        "try combining them into a voting ensemble, which will often give you even better results. It works better if the models are very different\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St_U3iyKroLD"
      },
      "source": [
        "**What is the difference between hard and soft voting classifiers?**\n",
        "\n",
        "A hard voting classifier just counts the votes of each classifier in the ensemble and picks the class that gets the most votes.\n",
        "\n",
        "A soft voting classifier computes the average estimated class probability for each class and picks the class with the highest probability.\n",
        "\n",
        "**Is it possible to speed up training of a bagging ensemble by distributing it across multiple servers? What about pasting ensembles, boosting ensembles, random forests, or stacking ensembles?**\n",
        "\n",
        "It is quite possible to speed up training of a bagging ensemble, pasting ensembles and Random Forests by distributing it across multiple servers, since each predictor in the ensemble is independent of the others.\n",
        "\n",
        "**What is the benefit of out-of-bag evaluation?**\n",
        "\n",
        "each predictor in a bagging ensemble is evaluated using instances that it was not trained on (they were held out).\n",
        "This makes it possible to have a fairly unbiased evaluation of the ensemble without the need for an additional validation set.\n",
        "Thus, you have more instances available for training, and your ensemble can perform slightly better.\n",
        "\n",
        "**What makes Extra-Trees more random than regular Random Forests? How can this extra randomness help? Are Extra-Trees slower or faster than regular Ran‚Äê dom Forests**\n",
        "\n",
        " extra is faster because it chosse any random split of data instead of splitting it on the best accuracy \n",
        "\n",
        "\n",
        "**If your AdaBoost ensemble underfits the training data, what hyperparameters should you tweak and how?**\n",
        "\n",
        "try increasing the number of estimators or reducing the regularization hyperparameters of the base estimator, also try slightly increasing the learning rate.\n",
        "\n",
        "\n",
        "**If your Gradient Boosting ensemble overfits the training set, should you increase or decrease the learning rate?**\n",
        "\n",
        "decreasing the learning rate, early stopping to find the right number of predictors (you probably have too many).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGDszeMIto1L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}